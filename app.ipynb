{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 工具集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 2134, which is longer than the specified 1000\n",
      "Created a chunk of size 1915, which is longer than the specified 1000\n",
      "Created a chunk of size 1091, which is longer than the specified 1000\n",
      "Created a chunk of size 1543, which is longer than the specified 1000\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised ServiceUnavailableError: The server is overloaded or not ready yet..\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\KG-Agent\\app.ipynb 单元格 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/KG-Agent/app.ipynb#W1sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m docs \u001b[39m=\u001b[39m loader\u001b[39m.\u001b[39mload()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/KG-Agent/app.ipynb#W1sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m ruff_texts \u001b[39m=\u001b[39m text_splitter\u001b[39m.\u001b[39msplit_documents(docs)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/KG-Agent/app.ipynb#W1sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m ruff_db \u001b[39m=\u001b[39m Chroma\u001b[39m.\u001b[39;49mfrom_documents(ruff_texts, embeddings, collection_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mruff\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/KG-Agent/app.ipynb#W1sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m ruff \u001b[39m=\u001b[39m RetrievalQA\u001b[39m.\u001b[39mfrom_chain_type(llm\u001b[39m=\u001b[39mllm, chain_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstuff\u001b[39m\u001b[39m\"\u001b[39m, retriever\u001b[39m=\u001b[39mruff_db\u001b[39m.\u001b[39mas_retriever())\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/KG-Agent/app.ipynb#W1sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# Tool search\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\47131\\.conda\\envs\\swanchain\\lib\\site-packages\\langchain\\vectorstores\\chroma.py:646\u001b[0m, in \u001b[0;36mChroma.from_documents\u001b[1;34m(cls, documents, embedding, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[0;32m    644\u001b[0m texts \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mpage_content \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[0;32m    645\u001b[0m metadatas \u001b[39m=\u001b[39m [doc\u001b[39m.\u001b[39mmetadata \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents]\n\u001b[1;32m--> 646\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mfrom_texts(\n\u001b[0;32m    647\u001b[0m     texts\u001b[39m=\u001b[39mtexts,\n\u001b[0;32m    648\u001b[0m     embedding\u001b[39m=\u001b[39membedding,\n\u001b[0;32m    649\u001b[0m     metadatas\u001b[39m=\u001b[39mmetadatas,\n\u001b[0;32m    650\u001b[0m     ids\u001b[39m=\u001b[39mids,\n\u001b[0;32m    651\u001b[0m     collection_name\u001b[39m=\u001b[39mcollection_name,\n\u001b[0;32m    652\u001b[0m     persist_directory\u001b[39m=\u001b[39mpersist_directory,\n\u001b[0;32m    653\u001b[0m     client_settings\u001b[39m=\u001b[39mclient_settings,\n\u001b[0;32m    654\u001b[0m     client\u001b[39m=\u001b[39mclient,\n\u001b[0;32m    655\u001b[0m     collection_metadata\u001b[39m=\u001b[39mcollection_metadata,\n\u001b[0;32m    656\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    657\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\47131\\.conda\\envs\\swanchain\\lib\\site-packages\\langchain\\vectorstores\\chroma.py:610\u001b[0m, in \u001b[0;36mChroma.from_texts\u001b[1;34m(cls, texts, embedding, metadatas, ids, collection_name, persist_directory, client_settings, client, collection_metadata, **kwargs)\u001b[0m\n\u001b[0;32m    582\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Create a Chroma vectorstore from a raw documents.\u001b[39;00m\n\u001b[0;32m    583\u001b[0m \n\u001b[0;32m    584\u001b[0m \u001b[39mIf a persist_directory is specified, the collection will be persisted there.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    599\u001b[0m \u001b[39m    Chroma: Chroma vectorstore.\u001b[39;00m\n\u001b[0;32m    600\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    601\u001b[0m chroma_collection \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(\n\u001b[0;32m    602\u001b[0m     collection_name\u001b[39m=\u001b[39mcollection_name,\n\u001b[0;32m    603\u001b[0m     embedding_function\u001b[39m=\u001b[39membedding,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    608\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    609\u001b[0m )\n\u001b[1;32m--> 610\u001b[0m chroma_collection\u001b[39m.\u001b[39;49madd_texts(texts\u001b[39m=\u001b[39;49mtexts, metadatas\u001b[39m=\u001b[39;49mmetadatas, ids\u001b[39m=\u001b[39;49mids)\n\u001b[0;32m    611\u001b[0m \u001b[39mreturn\u001b[39;00m chroma_collection\n",
      "File \u001b[1;32mc:\\Users\\47131\\.conda\\envs\\swanchain\\lib\\site-packages\\langchain\\vectorstores\\chroma.py:188\u001b[0m, in \u001b[0;36mChroma.add_texts\u001b[1;34m(self, texts, metadatas, ids, **kwargs)\u001b[0m\n\u001b[0;32m    186\u001b[0m texts \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(texts)\n\u001b[0;32m    187\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_embedding_function \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 188\u001b[0m     embeddings \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embedding_function\u001b[39m.\u001b[39;49membed_documents(texts)\n\u001b[0;32m    189\u001b[0m \u001b[39mif\u001b[39;00m metadatas:\n\u001b[0;32m    190\u001b[0m     \u001b[39m# fill metadatas with empty dicts if somebody\u001b[39;00m\n\u001b[0;32m    191\u001b[0m     \u001b[39m# did not specify metadata for all texts\u001b[39;00m\n\u001b[0;32m    192\u001b[0m     length_diff \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(texts) \u001b[39m-\u001b[39m \u001b[39mlen\u001b[39m(metadatas)\n",
      "File \u001b[1;32mc:\\Users\\47131\\.conda\\envs\\swanchain\\lib\\site-packages\\langchain\\embeddings\\openai.py:490\u001b[0m, in \u001b[0;36mOpenAIEmbeddings.embed_documents\u001b[1;34m(self, texts, chunk_size)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Call out to OpenAI's embedding endpoint for embedding search docs.\u001b[39;00m\n\u001b[0;32m    479\u001b[0m \n\u001b[0;32m    480\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[39m    List of embeddings, one for each text.\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[39m# NOTE: to keep things simple, we assume the list may contain texts longer\u001b[39;00m\n\u001b[0;32m    489\u001b[0m \u001b[39m#       than the maximum context and use length-safe embedding function.\u001b[39;00m\n\u001b[1;32m--> 490\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_len_safe_embeddings(texts, engine\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdeployment)\n",
      "File \u001b[1;32mc:\\Users\\47131\\.conda\\envs\\swanchain\\lib\\site-packages\\langchain\\embeddings\\openai.py:374\u001b[0m, in \u001b[0;36mOpenAIEmbeddings._get_len_safe_embeddings\u001b[1;34m(self, texts, engine, chunk_size)\u001b[0m\n\u001b[0;32m    371\u001b[0m     _iter \u001b[39m=\u001b[39m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(tokens), _chunk_size)\n\u001b[0;32m    373\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m _iter:\n\u001b[1;32m--> 374\u001b[0m     response \u001b[39m=\u001b[39m embed_with_retry(\n\u001b[0;32m    375\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[0;32m    376\u001b[0m         \u001b[39minput\u001b[39m\u001b[39m=\u001b[39mtokens[i : i \u001b[39m+\u001b[39m _chunk_size],\n\u001b[0;32m    377\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_invocation_params,\n\u001b[0;32m    378\u001b[0m     )\n\u001b[0;32m    379\u001b[0m     batched_embeddings\u001b[39m.\u001b[39mextend(r[\u001b[39m\"\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m response[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m    381\u001b[0m results: List[List[List[\u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m [[] \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(texts))]\n",
      "File \u001b[1;32mc:\\Users\\47131\\.conda\\envs\\swanchain\\lib\\site-packages\\langchain\\embeddings\\openai.py:107\u001b[0m, in \u001b[0;36membed_with_retry\u001b[1;34m(embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m     response \u001b[39m=\u001b[39m embeddings\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    105\u001b[0m     \u001b[39mreturn\u001b[39;00m _check_response(response, skip_empty\u001b[39m=\u001b[39membeddings\u001b[39m.\u001b[39mskip_empty)\n\u001b[1;32m--> 107\u001b[0m \u001b[39mreturn\u001b[39;00m _embed_with_retry(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\47131\\.conda\\envs\\swanchain\\lib\\site-packages\\tenacity\\__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[1;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(f, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\47131\\.conda\\envs\\swanchain\\lib\\site-packages\\tenacity\\__init__.py:389\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoSleep):\n\u001b[0;32m    388\u001b[0m     retry_state\u001b[39m.\u001b[39mprepare_for_next_attempt()\n\u001b[1;32m--> 389\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msleep(do)\n\u001b[0;32m    390\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    391\u001b[0m     \u001b[39mreturn\u001b[39;00m do\n",
      "File \u001b[1;32mc:\\Users\\47131\\.conda\\envs\\swanchain\\lib\\site-packages\\tenacity\\nap.py:31\u001b[0m, in \u001b[0;36msleep\u001b[1;34m(seconds)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msleep\u001b[39m(seconds: \u001b[39mfloat\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[39m    Sleep strategy that delays execution for a given number of seconds.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m \u001b[39m    This is the default strategy, and may be mocked out for unit testing.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     time\u001b[39m.\u001b[39;49msleep(seconds)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Tool webloader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "loader = WebBaseLoader(\"https://beta.ruff.rs/docs/faq/\")\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "\n",
    " \n",
    "embeddings = OpenAIEmbeddings()\n",
    "docs = loader.load()\n",
    "ruff_texts = text_splitter.split_documents(docs)\n",
    "ruff_db = Chroma.from_documents(ruff_texts, embeddings, collection_name=\"ruff\")\n",
    "ruff = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=ruff_db.as_retriever())\n",
    "\n",
    "\n",
    "\n",
    "# Tool search\n",
    "from langchain import LLMMathChain, SerpAPIWrapper\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "\n",
    "search = SerpAPIWrapper(serpapi_api_key=\"put your key here\")\n",
    "search_tool = Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AgentType\n",
    "经测试ZERO_SHOT_REACT_DESCRIPTION即可很好满足需要，同时只要将search工具放在最后一个，就能实现先调用已有工具最后再使用search，反之则会无脑先使用Search。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m 我需要找到Ruff的相关信息\n",
      "Action: Search\n",
      "Action Input: Ruff\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'type': 'dictionary_results', 'syllables': 'ruff', 'phonetic': '/rəf/', 'word_type': 'noun'}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m 我需要更多的信息\n",
      "Action: Ruff QA System\n",
      "Action Input: What is Ruff?\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m Ruff is a linter and formatter for Python code written in Rust. It is compatible with Flake8 plugins, but uses different rule codes and prefixes to minimize conflicts. It does not support custom lint rules, but popular Flake8 plugins are re-implemented in Rust as part of Ruff itself.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m 我现在知道最终答案了\n",
      "Final Answer: Ruff是一个用Rust编写的Python代码的语法检查器和格式化器，它与Flake8插件兼容，但使用不同的规则代码和前缀以最大限度地减少冲突。它不支持自定义lint规则，但是常用的Flake8插件作为Ruff本身的一部分，已经在Rust中重新实现。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ruff是一个用Rust编写的Python代码的语法检查器和格式化器，它与Flake8插件兼容，但使用不同的规则代码和前缀以最大限度地减少冲突。它不支持自定义lint规则，但是常用的Flake8插件作为Ruff本身的一部分，已经在Rust中重新实现。'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import things that are needed generically\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain.tools import BaseTool\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name = \"Ruff QA System\",\n",
    "        func=ruff.run,\n",
    "        description=\"useful for when you need to answer questions about ruff (a python linter). Input should be a fully formed question.\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "# Construct the agent. We will use the default agent type here.\n",
    "# See documentation for a full list of options.\n",
    "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
    "\n",
    "#询问指定文件内容\n",
    "agent.run(\"介绍一下Ruff?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m 我需要找到一些有关OpenAI Dev Day的信息\n",
      "Action: Search\n",
      "Action Input: OpenAI Dev Day\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[{'title': 'Everything announced at OpenAI’s first developer event', 'link': 'https://techcrunch.com/2023/11/06/everything-announced-at-openais-first-developer-event/', 'source': 'TechCrunch', 'date': '2 hours ago', 'thumbnail': 'https://serpapi.com/searches/6549ff08681ebea18151f459/images/0bffca266b3e3f5b139a4590ef4442ab678bff9fab1528a4.jpeg'}, {'title': 'OpenAI creates market for custom ChatGPTs', 'link': 'https://www.axios.com/2023/11/06/open-ai-dev-day-chatgpt-custom', 'source': 'Axios', 'date': '8 hours ago', 'thumbnail': 'https://serpapi.com/searches/6549ff08681ebea18151f459/images/0bffca266b3e3f5bc6df56ba4f2e87c61be5e958fb0abb66.jpeg'}, {'title': 'OpenAI unveils custom GPTs, Store, and Assistant API, at Dev Day', 'link': 'https://www.zdnet.com/article/openai-unveils-custom-gpts-store-and-assistant-api-at-dev-day/', 'source': 'ZDNet', 'date': '10 hours ago', 'thumbnail': 'https://serpapi.com/searches/6549ff08681ebea18151f459/images/0bffca266b3e3f5b88d41fd088820ca89284a6a97e892e1d.jpeg'}, {'title': 'GPT-4 Turbo, GPT Store & Assistants API: 9 big takeaways from OpenAI DevDay 2023', 'link': 'https://indianexpress.com/article/technology/artificial-intelligence/openai-devday-2023-key-takeaways-sam-altman-9016383/', 'source': 'The Indian Express', 'date': '13 hours ago', 'thumbnail': 'https://serpapi.com/searches/6549ff08681ebea18151f459/images/0bffca266b3e3f5bc025e24eeb3048a6adf55dc3bedd52b7.jpeg'}, {'title': 'Techies see OpenAI DevDay keynote as important as iPhone launch', 'link': 'https://www.businessinsider.com/openai-dev-day-gets-ai-developers-hyped-2023-11', 'source': 'Business Insider', 'date': '20 hours ago', 'thumbnail': 'https://serpapi.com/searches/6549ff08681ebea18151f459/images/0bffca266b3e3f5bffc8b01c219d6ad50f7f4fd23054af7e.jpeg'}, {'title': 'OpenAI Leaks Ahead of Dev Day - Plus, a Synthedia Developer Panel and Watch Party', 'link': 'https://synthedia.substack.com/p/openai-leaks-ahead-of-dev-day-plus', 'date': '2 days ago', 'thumbnail': 'https://serpapi.com/searches/6549ff08681ebea18151f459/images/0bffca266b3e3f5b409709044869b85dc59cc627cd1b94ea.jpeg'}, {'link': 'https://twitter.com/jeremyphoward?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor', 'date': '6 hours ago'}, {'link': 'https://twitter.com/gdb?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor', 'date': '12 hours ago'}]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m 我现在可以从上面的结果中收集信息\n",
      "Action: Search\n",
      "Action Input: OpenAI Dev Day overview\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m['At its first developer day event, OpenAI launched a new Assistants API, to let developers build their own “agent-like experiences.” Developers ...']\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m 我现在可以得出最终答案\n",
      "Final Answer: OpenAI在其首次开发者日活动中推出了一个新的助手API，让开发人员构建自己的“代理类体验”。开发人员可以使用OpenAI的GPT-4 Turbo模型，以及新的GPT Store，来构建自定义的聊天机器人。\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'OpenAI在其首次开发者日活动中推出了一个新的助手API，让开发人员构建自己的“代理类体验”。开发人员可以使用OpenAI的GPT-4 Turbo模型，以及新的GPT Store，来构建自定义的聊天机器人。'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#搜索\n",
    "agent.run(\"介绍一下OpenAI Dev Day?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to find out what tools Ruff replaces.\n",
      "Action: Search\n",
      "Action Input: \"What tools does Ruff replace?\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mRuff can be used to replace Flake8 (plus dozens of plugins), isort, pydocstyle, yesqa, eradicate, pyupgrade, and autoflake, all while executing tens or hundreds of times faster than any individual tool. This has the potential to simplify and speed up our code checks massively.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: Ruff can replace Flake8 (plus dozens of plugins), isort, pydocstyle, yesqa, eradicate, pyupgrade, and autoflake.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ruff can replace Flake8 (plus dozens of plugins), isort, pydocstyle, yesqa, eradicate, pyupgrade, and autoflake.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"Ruff取代了哪些工具?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\47131\\.conda\\envs\\swanchain\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\47131\\.conda\\envs\\swanchain\\lib\\site-packages\\gradio\\queueing.py\", line 427, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "  File \"c:\\Users\\47131\\.conda\\envs\\swanchain\\lib\\site-packages\\gradio\\route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"c:\\Users\\47131\\.conda\\envs\\swanchain\\lib\\site-packages\\gradio\\blocks.py\", line 1486, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"c:\\Users\\47131\\.conda\\envs\\swanchain\\lib\\site-packages\\gradio\\blocks.py\", line 1108, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"c:\\Users\\47131\\.conda\\envs\\swanchain\\lib\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"c:\\Users\\47131\\.conda\\envs\\swanchain\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"c:\\Users\\47131\\.conda\\envs\\swanchain\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"c:\\Users\\47131\\.conda\\envs\\swanchain\\lib\\site-packages\\gradio\\utils.py\", line 665, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\47131\\AppData\\Local\\Temp\\ipykernel_15000\\2721292961.py\", line 3, in answer\n",
      "    ans=agent.run(ask)\n",
      "NameError: name 'agent' is not defined. Did you mean: 'anext'?\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\47131\\.conda\\envs\\swanchain\\lib\\site-packages\\gradio\\queueing.py\", line 427, in call_prediction\n",
      "    output = await route_utils.call_process_api(\n",
      "  File \"c:\\Users\\47131\\.conda\\envs\\swanchain\\lib\\site-packages\\gradio\\route_utils.py\", line 232, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"c:\\Users\\47131\\.conda\\envs\\swanchain\\lib\\site-packages\\gradio\\blocks.py\", line 1486, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"c:\\Users\\47131\\.conda\\envs\\swanchain\\lib\\site-packages\\gradio\\blocks.py\", line 1108, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(\n",
      "  File \"c:\\Users\\47131\\.conda\\envs\\swanchain\\lib\\site-packages\\anyio\\to_thread.py\", line 33, in run_sync\n",
      "    return await get_asynclib().run_sync_in_worker_thread(\n",
      "  File \"c:\\Users\\47131\\.conda\\envs\\swanchain\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"c:\\Users\\47131\\.conda\\envs\\swanchain\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 807, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"c:\\Users\\47131\\.conda\\envs\\swanchain\\lib\\site-packages\\gradio\\utils.py\", line 665, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\47131\\AppData\\Local\\Temp\\ipykernel_15000\\2721292961.py\", line 3, in answer\n",
      "    ans=agent.run(ask)\n",
      "NameError: name 'agent' is not defined. Did you mean: 'anext'?\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\47131\\.conda\\envs\\swanchain\\lib\\site-packages\\gradio\\queueing.py\", line 472, in process_events\n",
      "    response = await self.call_prediction(awake_events, batch)\n",
      "  File \"c:\\Users\\47131\\.conda\\envs\\swanchain\\lib\\site-packages\\gradio\\queueing.py\", line 436, in call_prediction\n",
      "    raise Exception(str(error) if show_error else None) from error\n",
      "Exception: None\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "def answer(ask):\n",
    "    ans=agent.run(ask)\n",
    "    return ans\n",
    "\n",
    "\n",
    "ui = gr.Interface(fn=answer, inputs=gr.Textbox(label=\"请输入你想查询的信息：\"), outputs=\"text\",title = \"<h1 style='font-size: 40px;'><center>知识图谱问答</center></h1>\")\n",
    "ui.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swanchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
